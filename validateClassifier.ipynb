{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Evaluate Classification Models](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Evaluate Classification Models](#toc1_)    \n",
    "  - [Setup for evaluating the classifier](#toc1_1_)    \n",
    "  - [Prepare Dataloader](#toc1_2_)    \n",
    "    - [Standard ImageNet Validation Dataset](#toc1_2_1_)    \n",
    "  - [Prepare Model](#toc1_3_)    \n",
    "  - [Evaluate on ImageNet Validation Dataset](#toc1_4_)    \n",
    "    - [Evaluate by class](#toc1_4_1_)    \n",
    "    - [Save the results](#toc1_4_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18, mobilenet_v2\n",
    "\n",
    "from tools import data, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Setup for evaluating the classifier](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = {\n",
    "    \"data_path\": \"./data/imagewoof\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 90,\n",
    "    \"workers\": 16,\n",
    "    \"opt\": \"sgd\",\n",
    "    \"lr\": 0.1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0001,\n",
    "    \"label_smoothing\": 0.0,\n",
    "    \"mixup_alpha\": 0.0,\n",
    "    \"cutmix_alpha\": 0.0,\n",
    "    \"lr_scheduler\": \"steplr\",\n",
    "    \"lr_warmup_epochs\": 0,\n",
    "    \"lr_warmup_method\": \"constant\",\n",
    "    \"lr_warmup_decay\": 0.01,\n",
    "    \"lr_step_size\": 30,\n",
    "    \"lr_gamma\": 0.1,\n",
    "    \"lr_min\": 0.0,\n",
    "    \"print_freq\": 10,\n",
    "    \"output_dir\": \".\",\n",
    "    \"resume\": \"\",\n",
    "    \"start_epoch\": 0,\n",
    "    \"cache_dataset\": False,\n",
    "    \"sync_bn\": False,\n",
    "    \"test_only\": False,\n",
    "    \"ra_magnitude\": 9,\n",
    "    \"augmix_severity\": 3,\n",
    "    \"random_erase\": 0.0,\n",
    "    \"amp\": False,\n",
    "    \"world_size\": 1,\n",
    "    \"dist_url\": \"env://\",\n",
    "    \"model_ema\": False,\n",
    "    \"model_ema_steps\": 32,\n",
    "    \"model_ema_decay\": 0.99998,\n",
    "    \"use_deterministic_algorithms\": False,\n",
    "    \"interpolation\": \"bilinear\",\n",
    "    \"val_resize_size\": 256,\n",
    "    \"val_crop_size\": 224,\n",
    "    \"train_crop_size\": 224,\n",
    "    \"ra_sampler\": False,\n",
    "    \"ra_reps\": 3,\n",
    "    \"backend\": \"PIL\",\n",
    "    \"use_v2\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(setup['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup[\"batch_size\"] = 256\n",
    "setup[\"workers\"] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n"
     ]
    }
   ],
   "source": [
    "setup = utils.init_distributed_mode(setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Prepare Dataloader](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[Standard ImageNet Validation Dataset](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet10_val.pt dataset saved to ./data/imagewoof\n",
      "imagenet10_val.pt dataset loaded from ./data/imagewoof\n"
     ]
    }
   ],
   "source": [
    "# Load validation set\n",
    "data.cacheValData(\n",
    "    f'{setup[\"data_path\"].replace(\"./\",\"\")}/val',\n",
    "    \"imagenet10_val\",\n",
    "    save_path=setup[\"data_path\"],\n",
    ")\n",
    "\n",
    "val_dataset = data.loadData(\"imagenet10_val\", cache_path=setup[\"data_path\"])\n",
    "\n",
    "assert len(val_dataset.classes) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = val_dataset.class_to_idx\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "num_classes = len(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sampler = utils.getValSampler(val_dataset, setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=setup[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    sampler=val_sampler,\n",
    "    num_workers=setup[\"workers\"],\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_subsets = data.getSubsets(val_dataset, f\"{setup['data_path'].replace('./','')}/val\")\n",
    "val_loaders = data.getSubsetLoader(\n",
    "    val_subsets,\n",
    "    batch_size=setup[\"batch_size\"],\n",
    "    num_workers=setup[\"workers\"],\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Prepare Model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model weights\n",
    "model = resnet18(weights=None, num_classes=10)  # resnet18, mobilenet_v2\n",
    "eval_model_path = \"output/imagewoof/model_200.pth\"  # Path to the model for evaluation\n",
    "checkpoint = torch.load(eval_model_path)\n",
    "if \"setup\" in checkpoint:\n",
    "    if checkpoint[\"setup\"][\"distributed\"]:\n",
    "        torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint[\"model\"], \"module.\"\n",
    "        )\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "else:\n",
    "    model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_ema, model_without_ddp = utils.model_setup(model, setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Evaluate on ImageNet Validation Dataset](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=setup['label_smoothing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:   [ 0/16]  eta: 0:15:06  loss: 0.6389 (0.6389)  acc1: 80.8594 (80.8594)  acc5: 98.4375 (98.4375)  time: 56.6710  data: 55.7033  max mem: 1847\n",
      "Test:   [10/16]  eta: 0:00:31  loss: 0.6389 (0.6664)  acc1: 83.9844 (82.2798)  acc5: 98.8281 (98.1889)  time: 5.2129  data: 5.0641  max mem: 1855\n",
      "Test:  Total time: 0:00:59\n",
      "Test:  Acc@1 83.431 Acc@5 98.091\n"
     ]
    }
   ],
   "source": [
    "if model_ema:\n",
    "    metrics = utils.evaluate(\n",
    "        model_ema,\n",
    "        criterion,\n",
    "        data_loader_test,\n",
    "        device=device,\n",
    "        log_suffix=\"EMA\",\n",
    "        print_freq=setup[\"print_freq\"],\n",
    "    )\n",
    "else:\n",
    "    metrics = utils.evaluate(\n",
    "        model,\n",
    "        criterion,\n",
    "        data_loader_test,\n",
    "        device=device,\n",
    "        print_freq=setup[\"print_freq\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc1': 83.4308984474421,\n",
       " 'acc5': 98.09111733265462,\n",
       " 'loss': 0.6162927746772766,\n",
       " 'count': 16}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_val = metrics.copy()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_1_'></a>[Evaluate by class](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:   [0/2]  eta: 0:01:43  acc1: 80.8594 (80.8594)  acc5: 98.4375 (98.4375)  time: 51.7837  data: 51.2957  max mem: 1855\n",
      "Test:  Total time: 0:00:53\n",
      "Test:  Acc@1 82.152 Acc@5 98.533\n",
      "Test:   [0/2]  eta: 0:01:42  acc1: 89.4531 (89.4531)  acc5: 98.8281 (98.8281)  time: 51.1885  data: 51.0603  max mem: 1855\n",
      "Test:  Total time: 0:00:53\n",
      "Test:  Acc@1 87.990 Acc@5 99.265\n",
      "Test:   [0/2]  eta: 0:02:23  acc1: 77.3438 (77.3438)  acc5: 97.2656 (97.2656)  time: 71.6386  data: 71.4893  max mem: 1855\n",
      "Test:  Total time: 0:01:14\n",
      "Test:  Acc@1 77.512 Acc@5 97.847\n",
      "Test:   [0/1]  eta: 0:01:10  acc1: 65.6250 (65.6250)  acc5: 95.9821 (95.9821)  time: 70.9953  data: 70.8363  max mem: 1855\n",
      "Test:  Total time: 0:01:12\n",
      "Test:  Acc@1 65.625 Acc@5 95.982\n",
      "Test:   [0/2]  eta: 0:02:12  acc1: 83.5938 (83.5938)  acc5: 96.4844 (96.4844)  time: 66.1593  data: 65.9824  max mem: 1855\n",
      "Test:  Total time: 0:01:08\n",
      "Test:  Acc@1 83.791 Acc@5 96.509\n",
      "Test:   [0/2]  eta: 0:02:13  acc1: 82.8125 (82.8125)  acc5: 99.2188 (99.2188)  time: 66.9717  data: 66.7786  max mem: 1855\n",
      "Test:  Total time: 0:01:08\n",
      "Test:  Acc@1 82.801 Acc@5 99.263\n",
      "Test:   [0/2]  eta: 0:02:21  acc1: 86.3281 (86.3281)  acc5: 98.8281 (98.8281)  time: 70.8685  data: 70.6883  max mem: 1855\n",
      "Test:  Total time: 0:01:12\n",
      "Test:  Acc@1 85.536 Acc@5 98.504\n",
      "Test:   [0/2]  eta: 0:02:21  acc1: 89.4531 (89.4531)  acc5: 98.8281 (98.8281)  time: 70.8670  data: 70.6790  max mem: 1855\n",
      "Test:  Total time: 0:01:13\n",
      "Test:  Acc@1 87.204 Acc@5 99.052\n",
      "Test:   [0/2]  eta: 0:02:26  acc1: 91.0156 (91.0156)  acc5: 98.4375 (98.4375)  time: 73.2770  data: 73.0969  max mem: 1855\n",
      "Test:  Total time: 0:01:15\n",
      "Test:  Acc@1 91.841 Acc@5 98.834\n",
      "Test:   [0/2]  eta: 0:02:17  acc1: 79.6875 (79.6875)  acc5: 97.2656 (97.2656)  time: 68.8949  data: 68.6766  max mem: 1855\n",
      "Test:  Total time: 0:01:10\n",
      "Test:  Acc@1 81.463 Acc@5 96.098\n"
     ]
    }
   ],
   "source": [
    "eval_dict = dict()\n",
    "with torch.inference_mode():\n",
    "    for class_name, loader in val_loaders.items():\n",
    "        eval_dict[class_name] = dict()\n",
    "        if model_ema:\n",
    "            val_metrics, top_n_classes, conf_mean = utils.evaluateByClass(\n",
    "                model_ema,\n",
    "                loader,\n",
    "                num_classes,\n",
    "                device=device,\n",
    "                log_suffix=\"EMA\",\n",
    "                print_freq=setup[\"print_freq\"],\n",
    "            )\n",
    "        else:\n",
    "            val_metrics, top_n_classes, conf_mean = utils.evaluateByClass(\n",
    "                model,\n",
    "                loader,\n",
    "                num_classes,\n",
    "                device=device,\n",
    "                print_freq=setup[\"print_freq\"],\n",
    "            )\n",
    "        eval_dict[class_name][\"val_metrics\"] = val_metrics\n",
    "        eval_dict[class_name][\"top_n_classes\"] = [\n",
    "            idx_to_class[i] for i in top_n_classes\n",
    "        ]\n",
    "        eval_dict[class_name][\"correct_conf\"] = conf_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_2_'></a>[Save the results](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = dict()\n",
    "summary[\"eval_model\"] = eval_model_path\n",
    "summary[\"val_metrics\"] = real_val\n",
    "summary[\"val_metrics_details\"] = eval_dict\n",
    "summary[\"setup\"] = setup\n",
    "\n",
    "with open(\n",
    "    os.path.join(setup[\"data_path\"].replace(\"./\", \"\"), \"val.json\"),\n",
    "    \"w\",\n",
    ") as f:\n",
    "    json.dump(summary, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
